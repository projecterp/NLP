{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regexp = re.compile(r\"[^aeiouy]*[aeiouy]+[^aeiouy](\\w*)\")\n",
    "def get_r1(word):\n",
    "    # exceptional forms\n",
    "    if word.startswith('gener') or word.startswith('arsen'):\n",
    "        return 5\n",
    "    if word.startswith('commun'):\n",
    "        return 6\n",
    "\n",
    "    # normal form\n",
    "    match = regexp.match(word)\n",
    "    if match:\n",
    "        return match.start(1)\n",
    "    return len(word)\n",
    "\n",
    "def get_r2(word):\n",
    "    match = regexp.match(word, get_r1(word))\n",
    "    if match:\n",
    "        return match.start(1)\n",
    "    return len(word)\n",
    "\n",
    "def ends_with_short_syllable(word):\n",
    "    if len(word) == 2:\n",
    "        if re.match(r\"^[aeiouy][^aeiouy]$\", word):\n",
    "            return True\n",
    "    if re.match(r\".*[^aeiouy][aeiouy][^aeiouywxY]$\", word):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_short_word(word):\n",
    "    if ends_with_short_syllable(word):\n",
    "        if get_r1(word) == len(word):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def remove_initial_apostrophe(word):\n",
    "    if word.startswith(\"'\"):\n",
    "        return word[1:]\n",
    "    return word\n",
    "\n",
    "def capitalize_consonant_ys(word):\n",
    "    if word.startswith('y'):\n",
    "        word = 'Y' + word[1:]\n",
    "    return re.sub(r\"([aeiouy])y\", '\\g<1>Y', word)\n",
    "\n",
    "def step_0(word):\n",
    "    if word.endswith(\"'s'\"):\n",
    "        return word[:-3]\n",
    "    if word.endswith(\"'s\"):\n",
    "        return word[:-2]\n",
    "    if word.endswith(\"'\"):\n",
    "        return word[:-1]\n",
    "    return word\n",
    "\n",
    "def step_1a(word):\n",
    "    if word.endswith('sses'):\n",
    "        return word[:-4] + 'ss'\n",
    "    if word.endswith('ied') or word.endswith('ies'):\n",
    "        if len(word) > 4:\n",
    "            return word[:-3] + 'i'\n",
    "        else:\n",
    "            return word[:-3] + 'ie'\n",
    "    if word.endswith('us') or word.endswith('ss'):\n",
    "        return word\n",
    "    if word.endswith('s'):\n",
    "        preceding = word[:-1]\n",
    "        if re.search(r\"[aeiouy].\", preceding):\n",
    "            return preceding\n",
    "        return word\n",
    "    return word\n",
    "\n",
    "def step_1b(word, r1):\n",
    "    if word.endswith('eedly'):\n",
    "        if len(word) - 5 >= r1:\n",
    "            return word[:-3]\n",
    "        return word\n",
    "    if word.endswith('eed'):\n",
    "        if len(word) - 3 >= r1:\n",
    "            return word[:-1]\n",
    "        return word\n",
    "\n",
    "    def ends_with_double(word):\n",
    "        doubles = ['bb', 'dd', 'ff', 'gg', 'mm', 'nn', 'pp', 'rr', 'tt']\n",
    "        for double in doubles:\n",
    "            if word.endswith(double):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def step_1b_helper(word):\n",
    "        if word.endswith('at') or word.endswith('bl') or word.endswith('iz'):\n",
    "            return word + 'e'\n",
    "        if ends_with_double(word):\n",
    "            return word[:-1]\n",
    "        if is_short_word(word):\n",
    "            return word + 'e'\n",
    "        return word\n",
    "\n",
    "    suffixes = ['ed', 'edly', 'ing', 'ingly']\n",
    "    for suffix in suffixes:\n",
    "        if word.endswith(suffix):\n",
    "            preceding = word[:-len(suffix)]\n",
    "            if re.search(r\"[aeiouy]\", preceding):\n",
    "                return step_1b_helper(preceding)\n",
    "            return word\n",
    "\n",
    "    return word\n",
    "\n",
    "def step_1c(word):\n",
    "    if word.endswith('y') or word.endswith('Y'):\n",
    "        if word[-2] not in 'aeiouy':\n",
    "            if len(word) > 2:\n",
    "                return word[:-1] + 'i'\n",
    "    return word\n",
    "\n",
    "def step_2(word, r1):\n",
    "    def step_2_helper(end, repl, prev):\n",
    "        if word.endswith(end):\n",
    "            if len(word) - len(end) >= r1:\n",
    "                if prev == []:\n",
    "                    return word[:-len(end)] + repl\n",
    "                for p in prev:\n",
    "                    if word[:-len(end)].endswith(p):\n",
    "                        return word[:-len(end)] + repl\n",
    "            return word\n",
    "        return None\n",
    "\n",
    "    triples = [('ization', 'ize', []),\n",
    "               ('ational', 'ate', []),\n",
    "               ('fulness', 'ful', []),\n",
    "               ('ousness', 'ous', []),\n",
    "               ('iveness', 'ive', []),\n",
    "               ('tional', 'tion', []),\n",
    "               ('biliti', 'ble', []),\n",
    "               ('lessli', 'less', []),\n",
    "               ('entli', 'ent', []),\n",
    "               ('ation', 'ate', []),\n",
    "               ('alism', 'al', []),\n",
    "               ('aliti', 'al', []),\n",
    "               ('ousli', 'ous', []),\n",
    "               ('iviti', 'ive', []),\n",
    "               ('fulli', 'ful', []),\n",
    "               ('enci', 'ence', []),\n",
    "               ('anci', 'ance', []),\n",
    "               ('abli', 'able', []),\n",
    "               ('izer', 'ize', []),\n",
    "               ('ator', 'ate', []),\n",
    "               ('alli', 'al', []),\n",
    "               ('bli', 'ble', []),\n",
    "               ('ogi', 'og', ['l']),\n",
    "               ('li', '', ['c', 'd', 'e', 'g', 'h', 'k', 'm', 'n', 'r', 't'])]\n",
    "\n",
    "    for trip in triples:\n",
    "        attempt = step_2_helper(trip[0], trip[1], trip[2])\n",
    "        if attempt:\n",
    "            return attempt\n",
    "\n",
    "    return word\n",
    "\n",
    "def step_3(word, r1, r2):\n",
    "    def step_3_helper(end, repl, r2_necessary):\n",
    "        if word.endswith(end):\n",
    "            if len(word) - len(end) >= r1:\n",
    "                if not r2_necessary:\n",
    "                    return word[:-len(end)] + repl\n",
    "                else:\n",
    "                    if len(word) - len(end) >= r2:\n",
    "                        return word[:-len(end)] + repl\n",
    "            return word\n",
    "        return None\n",
    "\n",
    "    triples = [('ational', 'ate', False),\n",
    "               ('tional', 'tion', False),\n",
    "               ('alize', 'al', False),\n",
    "               ('icate', 'ic', False),\n",
    "               ('iciti', 'ic', False),\n",
    "               ('ative', '', True),\n",
    "               ('ical', 'ic', False),\n",
    "               ('ness', '', False),\n",
    "               ('ful', '', False)]\n",
    "\n",
    "    for trip in triples:\n",
    "        attempt = step_3_helper(trip[0], trip[1], trip[2])\n",
    "        if attempt:\n",
    "            return attempt\n",
    "\n",
    "    return word\n",
    "\n",
    "def step_4(word, r2):\n",
    "    delete_list = ['al', 'ance', 'ence', 'er', 'ic', 'able', 'ible', 'ant', 'ement', 'ment', 'ent', 'ism', 'ate', 'iti', 'ous', 'ive', 'ize']\n",
    "\n",
    "    for end in delete_list:\n",
    "        if word.endswith(end):\n",
    "            if len(word) - len(end) >= r2:\n",
    "                return word[:-len(end)]\n",
    "            return word\n",
    "\n",
    "    if word.endswith('sion') or word.endswith('tion'):\n",
    "        if len(word) - 3 >= r2:\n",
    "            return word[:-3]\n",
    "\n",
    "    return word\n",
    "\n",
    "def step_5(word, r1, r2):\n",
    "    if word.endswith('l'):\n",
    "        if len(word) - 1 >= r2 and word[-2] == 'l':\n",
    "            return word[:-1]\n",
    "        return word\n",
    "\n",
    "    if word.endswith('e'):\n",
    "        if len(word) - 1 >= r2:\n",
    "            return word[:-1]\n",
    "        if len(word) - 1 >= r1 and not ends_with_short_syllable(word[:-1]):\n",
    "            return word[:-1]\n",
    "\n",
    "    return word\n",
    "\n",
    "def normalize_ys(word):\n",
    "    return word.replace('Y', 'y')\n",
    "\n",
    "exceptional_forms = {'skis': 'ski',\n",
    "                    'skies': 'sky',\n",
    "                    'dying': 'die',\n",
    "                    'lying': 'lie',\n",
    "                    'tying': 'tie',\n",
    "                    'idly': 'idl',\n",
    "                    'gently': 'gentl',\n",
    "                    'ugly': 'ugli',\n",
    "                    'early': 'earli',\n",
    "                    'only': 'onli',\n",
    "                    'singly': 'singl',\n",
    "                    'sky': 'sky',\n",
    "                    'news': 'news',\n",
    "                    'howe': 'howe',\n",
    "                    'atlas': 'atlas',\n",
    "                    'cosmos': 'cosmos',\n",
    "                    'bias': 'bias',\n",
    "                    'andes': 'andes'}\n",
    "\n",
    "exceptional_early_exit_post_1a = ['inning', 'outing', 'canning', 'herring', 'earring', 'proceed', 'exceed', 'succeed']\n",
    "\n",
    "def stem(word):\n",
    "    \"\"\"The main entry point in the old version of the API.\"\"\"\n",
    "    raise DeprecationWarning('stem() is deprecated starting with v1.0.0')\n",
    "\n",
    "def algorithms():\n",
    "    \"\"\"Get a list of the names of the available stemming algorithms.\n",
    "\n",
    "    The only algorithm currently supported is the \"english\", or porter2,\n",
    "    algorithm.\n",
    "    \"\"\"\n",
    "    return ['english']\n",
    "\n",
    "def version ():\n",
    "    \"\"\"Get the version number of the stemming module.\n",
    "\n",
    "    This is the version number of the Stemmer module as a whole (not for an\n",
    "    individual algorithm).\n",
    "    \"\"\"\n",
    "    return '1.0.0'\n",
    "\n",
    "class Stemmer:\n",
    "    \"\"\"An instance of a stemming algorithm.\n",
    "\n",
    "    When creating a Stemmer object, there is one required argument:\n",
    "    the name of the algorithm to use in the new stemmer. A list of the\n",
    "    valid algorithm names may be obtained by calling the algorithms()\n",
    "    function in this module. In addition, the appropriate stemming algorithm\n",
    "    for a given language may be obtained by using the 2 or 3 letter ISO 639\n",
    "    language codes.\n",
    "    \"\"\"\n",
    "    max_cache_size = 10000\n",
    "\n",
    "    def __init__ (self, algorithm, cache_size=None):\n",
    "        if algorithm not in ['english', 'eng', 'en']:\n",
    "            raise KeyError(\"Stemming algorithm '%s' not found\" % algorithm)\n",
    "        if cache_size:\n",
    "            self.max_cache_size = cache_size\n",
    "\n",
    "    def stemWord(self, word):\n",
    "        \"\"\"Stem a word.\n",
    "\n",
    "        This takes a single argument, word, which should either be a UTF-8\n",
    "        encoded string, or a unicode object.\n",
    "\n",
    "        The result is the stemmed form of the word. If the word supplied\n",
    "        was a unicode object, the result will be a unicode object: if the\n",
    "        word supplied was a string, the result will be a UTF-8 encoded string.\n",
    "        \"\"\"\n",
    "        return Stemmer._stem(word)\n",
    "\n",
    "    def stemWords(self, words):\n",
    "        \"\"\"Stem a list of words.\n",
    "\n",
    "        This takes a single argument, words, which must be a sequence,\n",
    "        iterator, generator or similar.\n",
    "\n",
    "        The entries in words should either be UTF-8 encoded strings,\n",
    "        or a unicode objects.\n",
    "\n",
    "        The result is a list of the stemmed forms of the words. If the word\n",
    "        supplied was a unicode object, the stemmed form will be a unicode\n",
    "        object: if the word supplied was a string, the stemmed form will\n",
    "        be a UTF-8 encoded string.\n",
    "        \"\"\"\n",
    "        return [self.stemWord(word) for word in words]\n",
    "\n",
    "    @classmethod\n",
    "    def _stem(cls, word):\n",
    "        was_unicode = False\n",
    "\n",
    "        if isinstance(word, unicode):\n",
    "            was_unicode = True\n",
    "            try:\n",
    "                word = word.encode('ascii')\n",
    "            except:\n",
    "                return word\n",
    "\n",
    "        if len(word) <= 2:\n",
    "            return word\n",
    "        word = remove_initial_apostrophe(word)\n",
    "\n",
    "        # handle some exceptional forms\n",
    "        if word in exceptional_forms:\n",
    "            return exceptional_forms[word]\n",
    "\n",
    "        word = capitalize_consonant_ys(word)\n",
    "        r1 = get_r1(word)\n",
    "        r2 = get_r2(word)\n",
    "        word = step_0(word)\n",
    "        word = step_1a(word)\n",
    "\n",
    "        # handle some more exceptional forms\n",
    "        if word in exceptional_early_exit_post_1a:\n",
    "            return word\n",
    "\n",
    "        word = step_1b(word, r1)\n",
    "        word = step_1c(word)\n",
    "        word = step_2(word, r1)\n",
    "        word = step_3(word, r1, r2)\n",
    "        word = step_4(word, r2)\n",
    "        word = step_5(word, r1, r2)\n",
    "        word = normalize_ys(word)\n",
    "\n",
    "        return word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
